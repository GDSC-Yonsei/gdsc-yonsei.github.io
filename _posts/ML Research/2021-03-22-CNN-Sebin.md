---
published : true
title: "[ML Research]CNN"
date: 2021-03-22
excerpt: "CNN에 대하여 알아보는 포스트입니다."
use_math: true
categories:
  - MLResearch
author : SeBin Oh
---

<br/>

안녕하세요~ 여러분! 😄  
오늘은 CCN에 대하여 알아보려고 합니다.

<br/>

목차는 다음과 같습니다.

<br/>

### 📖 목차
- [CNN의 역사](#-cnn의-역사)
- [CNN이란 ?](#-cnn이란-)
  - [CNN의 구조](#-cnn의-구조)
  - [합성곱 계층](#-합성곱-계층-convolutional-layer-conv-layer)
  - [풀링 계층](#-풀링-계층pooling-layer)



<br/>

CNN이란 무엇인가? 에 대해 하나하나 살펴보시죠!

<br/>

## 📚 CNN의 역사

<br/>

생물학자 데이비드 허블(David H. Hubel)과 토르스튼 위즐(Torsten Wiesel)은 1958~1959년에 고양이 실험을 통하여 시각 피질의 구조에 대한 결정적인 통찰을 얻게 됩니다. 이들은 시각 피질 안의 많은 뉴런이 작은 국부 수용영역(local receptive field)을 가진다는 것을 보였는데, 이는 뉴런들이 시야의 일부 범위 안에 있는 시각 자극에만 반응을 한다는 것을 의미합니다. 뉴런의 수용영역(receptive field)들은 서로 겹칠 수 있으며 이렇게 겹쳐진 수용영역들이 전체 시야를 이루게 되는데, 어떤 뉴런은 수직선의 이미지에만, 어떤 뉴런은 다른 각도의 선에, 어떤 뉴런은 큰 수용영역을 가져 저수준의 패턴(edge, blob 등)이 조합되어 복잡한 패턴(texture, object)에 반응한다는 것을 발견한 것입니다. 이러한 관찰을 통하여 이들은 고수준의 뉴런이 이웃한 저수준의 뉴런의 출력에 기반한다는 아이디어를 도출해냈습니다.

한마디로 요약하자면 고양이가 바라보는 시각에 따라 자극받는 뇌 안의 위치가 다르다는 실험을 통하여 CNN의 새싹🌱이 자라게 됩니다.

<br/>

![Image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile22.uf.tistory.com%2Fimage%2F99F879415BC97DDD0B0E68)

(출처 : brainconnection)

<br/>

이 아이디어를 시작으로 1998년 컴퓨터 과학자 얀 리쿤(Yann Lecn)의 논문에서 손글씨 숫자를 인식하는데 사용한 LeNet-5가 소개되면서 합성곱 신경망(CNN, Convolutional Neural Network)이 처음 등장하였고, 2003년 Behnke의 논문을 통해 일반화, Simard의 논문을 통해 단순화되어 이후 GP GPU를 통하여 CNN을 구현할 수 있는 방법이 소개되어 지금은 DBN 등 많은 분야에서 활발하게 연구 및 진행되고 있습니다.

<br/>

|Year|Who|
|:--:|:--:|
|1998|Yann Lecn|
|2003|Behnke|
|2003|Simard|
|2003~|~ Ongoing ~|

<br/>

그러면 CNN은 무엇을 말하는 걸까요?

<br/>

## 💾 CNN이란 ?

<br/>

1989년 인간의 시신경 구조를 모방하여 만들어진 인공신경망 알고리즘을 말합니다. 다수의 합성곱 레이어(Convoulutional Layer)를 이용하여 입력 데이터로부터 특성맵(Feature map)을 추출하고 서브 샘플링(Subsampling)을 통해 차원을 축소하여 특성맵에서 출력 데이터를 결정하는 과정을 거칩니다. 이미지 분류, 얼굴 인식, 비디오 분석 등 대부분의 컴퓨터 비전(computer vision)분야에서 필수적으로 사용되는 기술이며, 기존의 mlp에 비하여 적은 연산량과 높은 성능을 갖추고 있습니다.

<br/>

자, 이제 CNN에 대해 자세히 하나하나 살펴보겠습니다!

<br/>

### 🧮 CNN의 구조

CNN의 구조는 완전 연결(fully connected)계층과는 달리 합성곱층(covolutional layer)과 풀링층(pooling layer)으로 구성되어 있습니다.

<br/>

![Image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile6.uf.tistory.com%2Fimage%2F996DCB355BC97DFF1C9B9A)

[ FC 와 CNN의 구조적 차이 ]  
(출처 : 밑바닥부터 시작하는 딥러닝)

<br/>

> ### 기존 MLNN(Multi-Layer Neural Network)의 문제점

<br/>

* **변수의 개수**
* **네크워크 크기**
* **학습 시간**

<br/>

예를 들어 MLNN을 이용하여 16 * 16 크기의 폰트를 갖는 필기체를 인식하는 네트워크를 있다고 가정을 합니다. 256개의 입력단과 100개의 hidden unit 및 26개의 출력단으로 구성된 경우(hidden-layer 1개로만 이루어진 단순한 구조), 이 네트워크의 가중치(weight)와 편향(bias)은 총 28,326개가 필요하게 됩니다.  
만약, hidden layer가 2단 이상이거나, 폰트의 크기 상향, 대소문자 또는 숫자를 구별하게 된다면 파라미터 개수는 더 많아지게 될 것입니다.
그리고 글자를 전체적으로 2 픽셀 씩 이동하게 되면 새로운 학습데이터로 처리해줘야 하는 문제점이 있을 뿐만 아니라, 글자의 크기가 달라지거나, 회전하거나, 변형이 생기게 되면, 이에 대한 새로운 학습 데이터를 넣어줘야 한다는 문제점이 발생합니다.  

결과적으로 글자의 형상은 고려하지 않고, raw data를 직접 처리하기 때문에 많은 양의 학습 데이터와 학습시간을 필요로 한다는 문제점이 발생합니다.

<br/>

![Image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile21.uf.tistory.com%2Fimage%2F25406B3358F470F135AABE)

[MLNN의 문제점]

<br/>

### 💻 합성곱 계층 (Convolutional layer, Conv Layer)

이러한 MLNN의 문제를 해결하고자 합성곱 계층이 등장하였습니다. 위의 필기체나 MNIST 데이터와 같은 이미지 데이터는 일반적으로

<br/>

* **세로**
* **가로**
* **채널**

<br/>

3차원으로 구성된 데이터입니다. 합성곱에서는 3차원 데이터를 입력하고 3차원의 데이터로 출력하므로 형상을 유지할 수 있는데, 이러한 입출력 데이터를 특성맵이라고 부릅니다.

<br/>

> ### 완전 연결 계층의 문제점 극복

<br/>

이전에 사용되던 완전 연결 계층(fully connected layer)을 이용하여 MNIST 데이터셋을 분류하는 모델을 만들 경우를 생각해봅니다.
3차원(세로, 가로, 채널)인 MNIST 데이터(28, 28, 1)를 입력층(input layer)에 넣어주기 위해서는 3차원에서 1차원의 평평한(flat) 데이터로 펼쳐야 합니다.

<br/>

![image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile3.uf.tistory.com%2Fimage%2F99A604375BC97E1422D519)

<br/>

이로 인하여 발생하는 문제점이 '데이터의 형상이 무시'된다는 것입니다. 이미지 데이터의 경우 3차원(세로, 가로, 채널)의 형상을 가지며, 이 형상에는 공간적으로 가까운 픽셀은 값이 비슷하거나, RGB의 각 채널은 서로 밀접하게 관련되어 있거나, 거리가 먼 픽셀끼리는 관련이 없는 등의 정보들이 내포된 공간적 구조(spatial structure)를 가집니다. 하지만, 완전 연결 계층에서 1차원의 데이터로 펼치게 되면 이러한 정보들이 사라지게 됩니다.

<br/>

그러나 합성곱층은 완전 연결 계층과는 달리 입력 데이터의 형상을 유지합니다. 3차원의 이미지 그대로 입력층에 입력받으며, 출력 또한 3차원 데이터로 출력하여 다음 계층(layer)으로 전달하기 때문에 CNN에서는 이미지 데이터처럼 형상을 가지는 데이터를 제대로 학습할 수 있습니다.

<br/>

![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile23.uf.tistory.com%2Fimage%2F99EC7D355BC97E41046974)

[Conv Layer에서의 입출력 데이터 형상]


<br/>

합성곱층의 뉴런은 입력 이미지의 모든 픽셀에 연결되는 것이 아니라 합성곱층 뉴런의 수용영역(receptive field) 안에 있는 픽셀에만 연결이 되기 때문에, 앞의 합성곱층에서는 저수준 특성에 집중하고, 그 다음 합성곱층에서는 고수준 특성으로 조합해 나가도록 해줍니다.

<br/>

![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile25.uf.tistory.com%2Fimage%2F9989933E5BC97E652B564A)
![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile5.uf.tistory.com%2Fimage%2F990A613B5BC97E7D1B7187)

(출처: towardsdatascience.com)

<br/>

이제는 합성곱을 세부적으로 알아보도록 합시다!

<br/>

> #### 필터(Filter)

<br/>

위에서 설명한 수용영역(receptive field)을 합성곱 계층에서 필터 또는 커널이라고 합니다. 필터는 합성곱 계층에서 가중치 파라미터(W)에 해당하며, 학습 단계에서 적절한 필터를 찾도록 학습합니다. 그리고 합성곱 계층에서 입력 데이터에 필터를 적용하여 필터와 유사한 이미지의 영역을 강조라는 특성맵을 출력 및 다음 층으로 전달하게 됩니다.

<br/>

![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile24.uf.tistory.com%2Fimage%2F99DF403C5BC97E912A1845)

<br/>

> #### 연산

<br/>

먼저 사전지식으로 데이터와 필터의 모양을 (높이, 너비)로 나타내며, 윈도우(window)라고 부릅니다. 예저에서 입력데이터는 (4, 4), 필터는 (3, 3)이며, 여기서 필터는 Conv Layer의 가중치에 해당합니다.  
합성곱 연산에서는 필터의 윈도우를 일정한 간격으로 이동해가며 계산합니다. 계산 방법을 알아보면, 입력데이터와 필터 간에 서로 대응하는 원소끼리 곱한 후 총합을 구하는데, 이것을 FMA(Fused Multiply-Add)라고 합니다. 마지막으로 편향은 필터를 적용한 후에 더해줍니다.

<br/>

![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile21.uf.tistory.com%2Fimage%2F99A440405BC97EDC20626B)

[합성곱 연산 예제]

<br/>

> #### 패딩(Padding)

<br/>

패딩은 합성곱 연산을 수행하기 전에 입력 데이터 주변을 특정값으로 채워 늘리는 것을 말합니다. 패딩은 출력 데이터의 공간적 크기를 조절하기 위해 사용하는데, 패딩을 할 때 채울 값은 hyperparameter로 결정할 수 있습니다. 주로 zero-padding을 사용합니다.  
패딩을 사용하는 이유는 사용하지 않을 경우, 데이터의 공간적 크기는 Conv Layer를 지날 때 마다 작아지게 되어 가장자리의 정보들이 사라지는 문제가 발생하기 때문입니다.

![image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile22.uf.tistory.com%2Fimage%2F9916C23F5BC97EEE31EF65)

> #### 스트라이드(Stride)

<br/>

스트라이드는 입력 데이터에 필터를 적용할 때 이동할 간격을 조절하는 것을 말합니다. 패딩과 마찬가지로 출력 데이터의 크기를 조절하기 위해 사용합니다. 스트라이드는 보통 1과 같은 작은 값이 더 잘 작동하며, 1일 경우 입력 데이터의 공간적 크기는 풀링 계층에서만 조절할 수 있습니다.

<br/>

![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile10.uf.tistory.com%2Fimage%2F2527FA3758F4785B13C548)

[zero-padding, stride 적용한 합성곱 연산]

<br/>

> #### 출력크기 계산

<br/>

패딩과 스트라이드를 적용하고, 입력 데이터와 필터의 크기가 주어졌을 때 출력 데이터의 크기를 구하는 식은 다음과 같습니다.

<br/>

![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile26.uf.tistory.com%2Fimage%2F27422F3358F479A62B1A66)

<br/>

출력크기가 정수가 아닌 경우 에러가 발생할 수 있는데, 보통 딥러닝 프레임워크에서는 반올림을 통해 에러없이 작동합니다.

<br/>

![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile25.uf.tistory.com%2Fimage%2F224F973A58F479E534FC83)
[출력 크기 계산 예제]

<br/>

이제까지는 합성곱 계층에 대해 알아보았습니다! CNN에는 합성곱 계층 이외에 다른 계층 또한 존재하는데, 바로 풀링 계층입니다.

<br/>

### 📺 풀링 계층(Pooling Layer)

<br/>

풀링 계층은 합성곱의 패딩과 스트라이트와 유사하게 데이터의 공간적 크기를 축소하는데 사용합니다.  
합성곱 계층과 풀링 계층의 역할은 다음과 같습니다.

<br/>

|합성곱 계층|풀링 계층|
|:--:|:--:|
|출력 데이터 크기를 입력 데이터 크기 그대로 유지|크기 조절|

<br/>

풀링의 배경에는 크게 기술적인 이유와 이론적인 이유가 존재합니다.  

<br/>

> #### 기술적인 측면

<br/>

풀링은 차례로 처리되는 데이터를 줄여 모델의 전체 매개변수의 수를 줄일 수 있습니다.  

* Max-pooling : 해당 영역의 최대값 찾는 방법  
Ex) 이미지 인식 분야  

* Average-pooling : 해당 영역의 평균값 찾는 방법

![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile24.uf.tistory.com%2Fimage%2F2366B34458F47D7808F54D)

[Max-pooling 예제]  

<br/>

> #### 이론적인 측면

<br/>

풀링은 계산된 특징으로 이미지 내의 위치에 대한 변화 영향을 덜 받습니다.  
예를 들어 이미지의 우측 상단에서 눈을 찾는 특징에서 눈이 이미지의 중앙에 위치하더라도 크게 영향을 받지 않아야 합니다. 그래서 풀링을 이용하여 불변성을 찾아내어 공간적 변화를 극복할 수 있습니다.

![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile7.uf.tistory.com%2Fimage%2F99E3903A5BC97FF426D00A)

<br/>

### 🤝 마치며

이상 CNN에 대해 간략히 알아보았습니다.  
이 포스트 내용 이외에 더 궁금하신 분은 아래의 글을 참고해주시길 바랍니다.

<br/>

### Reference

[https://excelsior-cjh.tistory.com/180](https://excelsior-cjh.tistory.com/180)

[https://hobinjeong.medium.com/cnn-convolutional-neural-network-9f600dd3b395](https://hobinjeong.medium.com/cnn-convolutional-neural-network-9f600dd3b395)

[https://blog.naver.com/PostView.nhn?blogId=laonple&logNo=221190581073&categoryNo=22&parentCategoryNo=0&viewDate=&currentPage=1&postListTopCurrentPage=1&from=postView&userTopListOpen=true&userTopListCount=10&userTopListManageOpen=false&userTopListCurrentPage=1](https://blog.naver.com/PostView.nhn?blogId=laonple&logNo=221190581073&categoryNo=22&parentCategoryNo=0&viewDate=&currentPage=1&postListTopCurrentPage=1&from=postView&userTopListOpen=true&userTopListCount=10&userTopListManageOpen=false&userTopListCurrentPage=1)

[https://www.youtube.com/watch?v=Em63mknbtWo&feature=youtu.be](https://www.youtube.com/watch?v=Em63mknbtWo&feature=youtu.be)

이현호. "CNN의 일반화 오류 평가 방법." 국내석사학위논문 부산대학교 대학원, 2020. 부산

이현수. "이미지 컨텐츠 검색을 위한 CNN의 구조." 국내석사학위논문 중앙대학교 대학원, 2018. 서울

<br/>

### 글쓴이

DSC Yonsei 오세빈

E-mail: [osb3372@yonsei.ac.kr](http://osb3372@yonsei.ac.kr)
